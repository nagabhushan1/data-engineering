{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Subquery Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT 'apple' AS fruit, 'carrot' AS vegetable\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTE (Common Table Expression) Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH groceries AS (\n",
    "  SELECT 'milk' AS dairy, 'eggs' AS protein, 'bread' AS grain\n",
    ")\n",
    "SELECT * FROM groceries\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using STRUCT in Spark SQL (with named_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH locations AS (\n",
    "  SELECT named_struct('city','Seattle','state','Washington') AS location\n",
    "  UNION ALL\n",
    "  SELECT named_struct('city','Phoenix','state','Arizona')\n",
    ")\n",
    "SELECT location.city, location.state FROM locations\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ARRAY of STRUCTs in Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH locations AS (\n",
    "  SELECT array(\n",
    "    struct('Seattle' AS city, 'Washington' AS state),\n",
    "    struct('Phoenix' AS city, 'Arizona' AS state)\n",
    "  ) AS location\n",
    ")\n",
    "SELECT location[0].city, location[0].state FROM locations\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting specific columns instead of EXCEPT (Spark does not support EXCEPT in SELECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH orders AS (\n",
    "  SELECT 5 AS order_id, 'sprocket' AS item_name, 200 AS quantity\n",
    ")\n",
    "SELECT item_name, quantity FROM orders\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing column value manually (instead of REPLACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH orders AS (\n",
    "  SELECT 5 AS order_id, 'sprocket' AS item_name, 200 AS quantity\n",
    ")\n",
    "SELECT order_id, 'widget' AS item_name, quantity FROM orders\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating value with calculation (instead of REPLACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH orders AS (\n",
    "  SELECT 5 AS order_id, 'sprocket' AS item_name, 200 AS quantity\n",
    ")\n",
    "SELECT order_id, item_name, quantity/2 AS quantity FROM orders\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with Produce dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH Produce AS (\n",
    "  SELECT 'Kale' AS product, 51 AS sales, 'Q1' AS quarter, 2020 AS year UNION ALL\n",
    "  SELECT 'Kale', 23, 'Q2', 2020 UNION ALL\n",
    "  SELECT 'Apple', 77, 'Q1', 2020\n",
    ")\n",
    "SELECT * FROM Produce\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with Sales dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH Sales AS (\n",
    "  SELECT 'Daisy' AS customer, DATE('2024-01-03') AS sale_date, 'Electronics' AS product_category, 500 AS amount UNION ALL\n",
    "  SELECT 'Daisy', DATE('2024-01-04'), 'Software', 30 UNION ALL\n",
    "  SELECT 'Ian', DATE('2024-02-01'), 'Books', 20\n",
    ")\n",
    "SELECT * FROM Sales\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
