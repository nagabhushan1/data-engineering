{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType"
      ],
      "metadata": {
        "id": "0I4GJIsj7tSv"
      },
      "id": "0I4GJIsj7tSv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Retail-Data-PySpark\").getOrCreate()\n",
        "INPUT_ROOT = \"/content\""
      ],
      "metadata": {
        "id": "X3CQTwCH7xkv"
      },
      "id": "X3CQTwCH7xkv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_schema = StructType([\n",
        "    StructField(\"order_id\", IntegerType(), True),\n",
        "    StructField(\"order_date\", TimestampType(), True),\n",
        "    StructField(\"order_customer_id\", IntegerType(), True),\n",
        "    StructField(\"order_status\", StringType(), True)\n",
        "])\n",
        "\n",
        "order_items_schema = StructType([\n",
        "    StructField(\"order_item_id\", IntegerType(), True),\n",
        "    StructField(\"order_item_order_id\", IntegerType(), True),\n",
        "    StructField(\"order_item_product_id\", IntegerType(), True),\n",
        "    StructField(\"order_item_quantity\", IntegerType(), True),\n",
        "    StructField(\"order_item_subtotal\", DoubleType(), True),\n",
        "    StructField(\"order_item_product_price\", DoubleType(), True)\n",
        "])\n",
        "\n",
        "customers_schema = StructType([\n",
        "    StructField(\"customer_id\", IntegerType(), True),\n",
        "    StructField(\"customer_fname\", StringType(), True),\n",
        "    StructField(\"customer_lname\", StringType(), True),\n",
        "    StructField(\"customer_email\", StringType(), True),\n",
        "    StructField(\"customer_password\", StringType(), True),\n",
        "    StructField(\"customer_street\", StringType(), True),\n",
        "    StructField(\"customer_city\", StringType(), True),\n",
        "    StructField(\"customer_state\", StringType(), True),\n",
        "    StructField(\"customer_zipcode\", StringType(), True)\n",
        "])\n",
        "\n",
        "categories_schema = StructType([\n",
        "    StructField(\"category_id\", IntegerType(), True),\n",
        "    StructField(\"category_department_id\", IntegerType(), True),\n",
        "    StructField(\"category_name\", StringType(), True)\n",
        "])\n",
        "\n",
        "products_schema = StructType([\n",
        "    StructField(\"product_id\", IntegerType(), True),\n",
        "    StructField(\"product_category_id\", IntegerType(), True),\n",
        "    StructField(\"product_name\", StringType(), True),\n",
        "    StructField(\"product_description\", StringType(), True),\n",
        "    StructField(\"product_price\", DoubleType(), True),\n",
        "    StructField(\"product_image\", StringType(), True)\n",
        "])\n",
        "\n",
        "departments_schema = StructType([\n",
        "    StructField(\"department_id\", IntegerType(), True),\n",
        "    StructField(\"department_name\", StringType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "oPhWro8B7edD"
      },
      "id": "oPhWro8B7edD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders = spark.read.option(\"header\", False).schema(orders_schema).csv(f\"{INPUT_ROOT}/orders.csv\")\n",
        "order_items = spark.read.option(\"header\", False).schema(order_items_schema).csv(f\"{INPUT_ROOT}/order_items.csv\")\n",
        "customers = spark.read.option(\"header\", False).schema(customers_schema).csv(f\"{INPUT_ROOT}/customers.csv\")\n",
        "categories = spark.read.option(\"header\", False).schema(categories_schema).csv(f\"{INPUT_ROOT}/categories.csv\")\n",
        "products = spark.read.option(\"header\", False).schema(products_schema).csv(f\"{INPUT_ROOT}/products.csv\")\n",
        "departments = spark.read.option(\"header\", False).schema(departments_schema).csv(f\"{INPUT_ROOT}/departments.csv\")\n"
      ],
      "metadata": {
        "id": "W5fvkF8e7hiX"
      },
      "id": "W5fvkF8e7hiX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders.createOrReplaceTempView(\"orders\")\n",
        "order_items.createOrReplaceTempView(\"order_items\")\n",
        "customers.createOrReplaceTempView(\"customers\")\n",
        "categories.createOrReplaceTempView(\"categories\")\n",
        "products.createOrReplaceTempView(\"products\")\n",
        "departments.createOrReplaceTempView(\"departments\")"
      ],
      "metadata": {
        "id": "vESA783J7jHI"
      },
      "id": "vESA783J7jHI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXiMHAkv7N5i"
      },
      "source": [
        "# Retail SQL â†’ Spark SQL Queries\n",
        "\n",
        "Each query is explained with a Markdown cell and executed in Spark SQL using `spark.sql()`."
      ],
      "id": "sXiMHAkv7N5i"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AHvYVpg7N5j"
      },
      "source": [
        "### 1. Distinct order status\n",
        "Taking distinct order statuses from the orders table and sorting them."
      ],
      "id": "9AHvYVpg7N5j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jVlgbmLu7N5k"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT DISTINCT order_status\n",
        "FROM orders\n",
        "ORDER BY order_status\n",
        "\"\"\").show()"
      ],
      "id": "jVlgbmLu7N5k"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHxs7r2a7N5l"
      },
      "source": [
        "### 2. Orders with COMPLETE status"
      ],
      "id": "XHxs7r2a7N5l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdia-P2w7N5l"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"SELECT * FROM orders WHERE order_status='COMPLETE'\").show()"
      ],
      "id": "zdia-P2w7N5l"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpZ224Mv7N5m"
      },
      "source": [
        "### 3. Orders with CLOSED status"
      ],
      "id": "VpZ224Mv7N5m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CC-MHR77N5m"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"SELECT * FROM orders WHERE order_status='CLOSED'\").show()"
      ],
      "id": "7CC-MHR77N5m"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82S7lj9m7N5m"
      },
      "source": [
        "### 4. Orders with CLOSED or COMPLETE status"
      ],
      "id": "82S7lj9m7N5m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbF9fexA7N5m"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"SELECT * FROM orders WHERE order_status IN ('CLOSED','COMPLETE')\").show()"
      ],
      "id": "LbF9fexA7N5m"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzl7hHO77N5n"
      },
      "source": [
        "### 5. Count of orders"
      ],
      "id": "Wzl7hHO77N5n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL3aaEen7N5n"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"SELECT COUNT(*) AS order_count FROM orders\").show()"
      ],
      "id": "xL3aaEen7N5n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFus71hr7N5n"
      },
      "source": [
        "### 6. Count of order items"
      ],
      "id": "iFus71hr7N5n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMDfgksi7N5n"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"SELECT COUNT(*) AS order_items_count FROM order_items\").show()"
      ],
      "id": "EMDfgksi7N5n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqI8WiCm7N5n"
      },
      "source": [
        "### 7. Count of distinct order statuses"
      ],
      "id": "NqI8WiCm7N5n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXqat_tm7N5o"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"SELECT COUNT(DISTINCT order_status) AS distinct_status_count FROM orders\").show()"
      ],
      "id": "jXqat_tm7N5o"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpx7-vsF7N5o"
      },
      "source": [
        "### 8. Order revenue per order"
      ],
      "id": "Hpx7-vsF7N5o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aw8ok3UP7N5o"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT order_item_order_id,\n",
        "       ROUND(SUM(order_item_subtotal),2) AS order_revenue\n",
        "FROM order_items\n",
        "GROUP BY order_item_order_id\n",
        "ORDER BY order_item_order_id\n",
        "\"\"\").show()"
      ],
      "id": "aw8ok3UP7N5o"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1B26T927N5o"
      },
      "source": [
        "### 9. Orders with >=120 per date"
      ],
      "id": "_1B26T927N5o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDWfhPZf7N5o"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT order_date, COUNT(*) AS order_count\n",
        "FROM orders\n",
        "WHERE order_status IN ('COMPLETE','CLOSED')\n",
        "GROUP BY order_date\n",
        "HAVING COUNT(*) >= 120\n",
        "ORDER BY order_count DESC\n",
        "\"\"\").show()"
      ],
      "id": "GDWfhPZf7N5o"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1aDULKU7N5o"
      },
      "source": [
        "### 10. Orders with revenue >=2000"
      ],
      "id": "v1aDULKU7N5o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ueh04Cfu7N5p"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT order_item_order_id,\n",
        "       ROUND(SUM(order_item_subtotal),2) AS order_revenue\n",
        "FROM order_items\n",
        "GROUP BY order_item_order_id\n",
        "HAVING ROUND(SUM(order_item_subtotal),2) >= 2000\n",
        "ORDER BY order_revenue DESC\n",
        "\"\"\").show()"
      ],
      "id": "Ueh04Cfu7N5p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jsTyw2a7N5p"
      },
      "source": [
        "### 11. Inner Join Orders + Order Items"
      ],
      "id": "0jsTyw2a7N5p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWSJ3KKD7N5p"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT o.order_date, oi.order_item_product_id, oi.order_item_subtotal\n",
        "FROM orders o\n",
        "JOIN order_items oi\n",
        "ON o.order_id = oi.order_item_order_id\n",
        "\"\"\").show()"
      ],
      "id": "RWSJ3KKD7N5p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvoGIaG67N5p"
      },
      "source": [
        "### 12. Left Outer Join Orders + Order Items"
      ],
      "id": "GvoGIaG67N5p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jHIrbSm7N5p"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT o.order_id, o.order_date,\n",
        "       oi.order_item_id, oi.order_item_product_id, oi.order_item_subtotal\n",
        "FROM orders o\n",
        "LEFT OUTER JOIN order_items oi\n",
        "ON o.order_id = oi.order_item_order_id\n",
        "ORDER BY o.order_id\n",
        "\"\"\").show()"
      ],
      "id": "1jHIrbSm7N5p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXzw3tnU7N5p"
      },
      "source": [
        "### 13. Daily Revenue temp view"
      ],
      "id": "kXzw3tnU7N5p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxAMaDeY7N5p"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE TEMP VIEW daily_revenue AS\n",
        "SELECT to_date(o.order_date) AS order_date,\n",
        "       ROUND(SUM(oi.order_item_subtotal),2) AS order_revenue\n",
        "FROM orders o\n",
        "JOIN order_items oi\n",
        "ON o.order_id = oi.order_item_order_id\n",
        "WHERE o.order_status IN ('COMPLETE','CLOSED')\n",
        "GROUP BY to_date(o.order_date)\n",
        "\"\"\")\n",
        "spark.sql(\"SELECT * FROM daily_revenue ORDER BY order_date\").show()"
      ],
      "id": "YxAMaDeY7N5p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olFgBhYj7N5q"
      },
      "source": [
        "### 14. Daily Product Revenue temp view"
      ],
      "id": "olFgBhYj7N5q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmOaJN0h7N5q"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE TEMP VIEW daily_product_revenue AS\n",
        "SELECT to_date(o.order_date) AS order_date,\n",
        "       oi.order_item_product_id,\n",
        "       ROUND(SUM(oi.order_item_subtotal),2) AS order_revenue\n",
        "FROM orders o\n",
        "JOIN order_items oi\n",
        "ON o.order_id = oi.order_item_order_id\n",
        "WHERE o.order_status IN ('COMPLETE','CLOSED')\n",
        "GROUP BY to_date(o.order_date), oi.order_item_product_id\n",
        "\"\"\")\n",
        "spark.sql(\"SELECT * FROM daily_product_revenue ORDER BY order_date, order_revenue DESC\").show()"
      ],
      "id": "cmOaJN0h7N5q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx3U-wqC7N5q"
      },
      "source": [
        "### 15. Monthly Revenue with Window"
      ],
      "id": "hx3U-wqC7N5q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFdn0fAX7N5q"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT date_format(dr.order_date,'yyyy-MM') AS order_month,\n",
        "       dr.order_date,\n",
        "       dr.order_revenue,\n",
        "       SUM(dr.order_revenue) OVER (PARTITION BY date_format(dr.order_date,'yyyy-MM')) AS monthly_order_revenue\n",
        "FROM daily_revenue dr\n",
        "ORDER BY dr.order_date\n",
        "\"\"\").show()"
      ],
      "id": "mFdn0fAX7N5q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzUg6h9W7N5q"
      },
      "source": [
        "### 16. Total Revenue with Window"
      ],
      "id": "RzUg6h9W7N5q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS0ELZ3P7N5q"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT dr.*,\n",
        "       SUM(order_revenue) OVER () AS total_order_revenue\n",
        "FROM daily_revenue dr\n",
        "ORDER BY dr.order_date\n",
        "\"\"\").show()"
      ],
      "id": "hS0ELZ3P7N5q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKfqDtHp7N5q"
      },
      "source": [
        "### 17. Top 5 Products per Day (Window)"
      ],
      "id": "oKfqDtHp7N5q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDxpJNl67N5q"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "WITH daily_product_revenue_ranks AS (\n",
        "  SELECT order_date,\n",
        "         order_item_product_id,\n",
        "         order_revenue,\n",
        "         RANK() OVER (PARTITION BY order_date ORDER BY order_revenue DESC) AS rnk,\n",
        "         DENSE_RANK() OVER (PARTITION BY order_date ORDER BY order_revenue DESC) AS drnk\n",
        "  FROM daily_product_revenue\n",
        "  WHERE date_format(order_date,'yyyy-MM')='2014-01'\n",
        ")\n",
        "SELECT *\n",
        "FROM daily_product_revenue_ranks\n",
        "WHERE drnk <= 5\n",
        "ORDER BY order_date, order_revenue DESC\n",
        "\"\"\").show()"
      ],
      "id": "XDxpJNl67N5q"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}